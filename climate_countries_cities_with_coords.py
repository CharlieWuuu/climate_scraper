import aiohttp
import asyncio
import csv
import os

# OpenStreetMap Nominatim API
nominatim_url = "https://nominatim.openstreetmap.org/search"

# è¨­å®šè¼¸å…¥ / è¼¸å‡º CSV æª”æ¡ˆ
input_file = "climate_countries_cities.csv"
output_file = "climate_countries_cities_with_coords.csv"

# è¨­å®šæœ€å¤§åŒæ™‚è«‹æ±‚æ•¸é‡ & æŸ¥è©¢ç­†æ•¸
MAX_CONCURRENT_REQUESTS = 3  # æ§åˆ¶ä¸¦ç™¼æ•¸é‡ï¼Œé¿å… API éè¼‰
BATCH_SIZE = 30  # æ¯æ¬¡æœ€å¤šæŸ¥è©¢ 30 ç­†ï¼Œç„¶å¾ŒçµæŸ

# **è®€å– climate_countries_cities.csv**
def get_all_city_data():
    city_data = {}  # å­˜æ”¾å®Œæ•´è³‡æ–™
    if os.path.exists(input_file):
        with open(input_file, mode="r", encoding="utf-8") as file:
            reader = csv.reader(file)
            next(reader, None)  # è·³éæ¨™é¡Œ
            for row in reader:
                city_id = int(row[0])
                city_data[city_id] = row[1:4]  # åªå­˜ `Country`ã€`Region`ã€`City`
    return city_data

# **è®€å– climate_countries_cities_with_coords.csv**
def get_existing_data():
    existing_data = {}  # å­˜æ”¾å·²æŸ¥è©¢éçš„è³‡æ–™
    if os.path.exists(output_file):
        with open(output_file, mode="r", encoding="utf-8") as file:
            reader = csv.reader(file)
            next(reader, None)  # è·³éæ¨™é¡Œ
            for row in reader:
                city_id = int(row[0])
                existing_data[city_id] = row  # å­˜æ•´è¡Œ
    return existing_data

# **æŸ¥è©¢å–®å€‹åŸå¸‚çš„ç¶“ç·¯åº¦**
async def fetch_coordinates(session, country, region, city):
    params = {"q": f"{country}, {region}, {city}", "format": "json", "limit": 1}
    headers = {"User-Agent": "MyProject/1.0 (charliewu500@gmail.com)"}

    try:
        async with session.get(nominatim_url, params=params, headers=headers, timeout=10) as response:
            if response.status != 200:
                print(f"âŒ {country}, {region}, {city}: HTTP {response.status} éŒ¯èª¤")
                return "N/A", "N/A"

            data = await response.json()
            if data:
                lat, lon = data[0]["lat"], data[0]["lon"]
                print(f"âœ… {country}, {region}, {city} â†’ {lat}, {lon}")
                return lat, lon
            else:
                print(f"âŒ {country}, {region}, {city}: æ‰¾ä¸åˆ°ç¶“ç·¯åº¦")
                return "N/A", "N/A"
    except Exception as e:
        print(f"âŒ {country}, {region}, {city}: é€£ç·šéŒ¯èª¤ - {e}")
        return "N/A", "N/A"

# **æ‰¹é‡æŸ¥è©¢ç¶“ç·¯åº¦**
async def fetch_all_coordinates(city_list):
    results = []
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)  # é™åˆ¶åŒæ™‚è«‹æ±‚æ•¸é‡

    async with aiohttp.ClientSession() as session:
        async def limited_fetch(city_id, country, region, city):
            async with semaphore:
                lat, lon = await fetch_coordinates(session, country, region, city)
                results.append([city_id, country, region, city, lat, lon])
                await asyncio.sleep(1.5)  # å¢åŠ è«‹æ±‚é–“éš”

        print(f"ğŸ” æ­£åœ¨æŸ¥è©¢ {len(city_list)} ç­†åŸå¸‚çš„ç¶“ç·¯åº¦...")
        tasks = [limited_fetch(city_id, country, region, city) for city_id, country, region, city in city_list]
        await asyncio.gather(*tasks)

    return results

# **è®€å– CSV ä¸¦åŸ·è¡ŒéåŒæ­¥æŸ¥è©¢**
async def main():
    city_data = get_all_city_data()  # è®€å– climate_countries_cities.csv
    existing_data = get_existing_data()  # è®€å– climate_countries_cities_with_coords.csv
    city_list = []
    all_results = []  # å­˜æ”¾æœ€çµ‚è³‡æ–™

    for city_id, (country, region, city) in sorted(city_data.items()):
        # **å¦‚æœ `Country`ã€`Region`ã€`City` éƒ½æ˜¯ `"-"`ï¼Œå‰‡ä¸æŸ¥è©¢**
        if country == "-" and region == "-" and city == "-":
            all_results.append([city_id, country, region, city, "N/A", "N/A"])
            continue  # è·³éæŸ¥è©¢

        if city_id in existing_data:
            row = existing_data[city_id]
            old_country, old_region, old_city, lat, lon = row[1:6]

            # **å¦‚æœè³‡æ–™ä¸åŒï¼Œæ›´æ–° Countryã€Regionã€Cityï¼Œä¸¦é‡æ–°æŸ¥è©¢**
            # if (old_country != country or old_region != region or old_city != city) or (lat == "N/A" or lon == "N/A"):
                # print(f"ğŸ”„ {city_id}: {old_country}, {old_region}, {old_city} â†’ {country}, {region}, {city} (é‡æ–°æŸ¥è©¢)")
                # city_list.append((city_id, country, region, city))
            # else:
            all_results.append(row)  # ä¿ç•™åŸè³‡æ–™
        else:
            # **æ–°çš„ ID éœ€è¦æŸ¥è©¢**
            city_list.append((city_id, country, region, city))

    # **é™åˆ¶æ¯æ¬¡æŸ¥è©¢ 30 ç­†**
    if city_list:
        city_list = city_list[:BATCH_SIZE]  # åªå–å‰ 30 ç­†
        print(f"ğŸ” é€™æ¬¡åŸ·è¡Œæœ€å¤šæŸ¥è©¢ {len(city_list)} ç­†")
        results = await fetch_all_coordinates(city_list)
        all_results.extend(results)  # åŠ å…¥æ–°çš„æŸ¥è©¢çµæœ
    else:
        print("âœ… æ‰€æœ‰åŸå¸‚çš„ç¶“ç·¯åº¦éƒ½å·²æŸ¥è©¢å®Œæˆï¼Œç„¡éœ€ç¹¼çºŒã€‚")

    # **ç¢ºä¿ ID é‡æ–°æ’åº**
    all_results.sort(key=lambda x: int(x[0]))

    # **å­˜å…¥ CSV**
    with open(output_file, mode="w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerow(["ID", "Country", "Region", "City", "Latitude", "Longitude"])  # å¯«å…¥æ¨™é¡Œ
        writer.writerows(all_results)

    print(f"âœ… ç¶“ç·¯åº¦æŸ¥è©¢å®Œæˆï¼Œå­˜å…¥ {output_file}ï¼Œé€™æ¬¡åŸ·è¡ŒçµæŸï¼")

# **åŸ·è¡Œ**
asyncio.run(main())
